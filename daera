#!/usr/bin/env bash

#  (Da'era) - Python Circular Dependency Analyzer
#  Tool to detect circular imports in Python projects
#
# Copyright (c) 2025 Mohamed Elashri
# https://github.com/MohamedElashri/daera
# 
# Licensed under MIT License

# -------- Color Definitions --------
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
GRAY='\033[0;90m'
BOLD='\033[1m'
UNDERLINE='\033[4m'
RESET='\033[0m'

# -------- Default Settings --------
VERBOSE=1        # Default verbosity level (0=quiet, 1=normal, 2=verbose, 3=debug)
PROJECT_DIR=""   # Default project directory (empty = no directory specified)
REPORT_FILE=""   # Output report file (empty = no file output)
GRAPH_OUTPUT=""  # Graph output file (empty = no graph generation)
EXCLUDE_DIRS=""  # Directories to exclude
EXCLUDE_FILES="" # Files to exclude
FOUND_CYCLES=0   # Counter for found cycles
MAX_DEPTH=100    # Maximum recursion depth for dependency resolution
MAX_WORKERS=8    # Maximum number of parallel workers (adjust based on CPU cores)
ONLY_PROJECT=1   # Only analyze project files, not external dependencies

# -------- Function Declarations --------

function show_banner() {
    if [[ $VERBOSE -ge 1 ]]; then
        echo -e "${BOLD}${BLUE}┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓${RESET}"
        echo -e "${BOLD}${BLUE}┃ (Da'era) - Circular Dependency Analyzer v1.0        ┃${RESET}"
        echo -e "${BOLD}${BLUE}┗━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┛${RESET}"
        echo
    fi
}

function show_help() {
    echo -e "${BOLD}Usage:${RESET}"
    echo -e "  daera [options] [directory]"
    echo
    echo -e "${BOLD}Options:${RESET}"
    echo -e "  ${GREEN}-h, --help${RESET}            Show this help message and exit"
    echo -e "  ${GREEN}-v, --verbose${RESET}         Increase verbosity level (can be used multiple times)"
    echo -e "  ${GREEN}-q, --quiet${RESET}           Quiet mode (no output except errors and results)"
    echo -e "  ${GREEN}-o, --output FILE${RESET}     Write report to FILE"
    echo -e "  ${GREEN}-g, --graph FILE${RESET}      Generate dependency graph in DOT format to FILE"
    echo -e "  ${GREEN}-e, --exclude DIR${RESET}     Exclude directory from analysis (can be used multiple times)"
    echo -e "  ${GREEN}-f, --exclude-file FILE${RESET} Exclude file from analysis (can be used multiple times)"
    echo -e "  ${GREEN}-d, --max-depth N${RESET}     Set maximum recursion depth for dependency resolution (default: 100)"
    echo -e "  ${GREEN}-j, --jobs N${RESET}          Number of parallel workers (default: 8)"
    echo -e "  ${GREEN}-a, --all${RESET}             Analyze all imported files, not just project files"
    echo
    echo -e "${BOLD}Examples:${RESET}"
    echo -e "  daera ~/projects/myproject"
    echo -e "  daera -vv -o report.txt -g deps.dot -e venv -e __pycache__ ."
    echo -e "  daera -j 16 ~/projects/large-project  # Use 16 parallel workers"
    echo
}

function log_debug() {
    if [[ $VERBOSE -ge 3 ]]; then
        echo -e "${GRAY}[DEBUG] $*${RESET}" >&2
    fi
}

function log_info() {
    if [[ $VERBOSE -ge 2 ]]; then
        echo -e "${CYAN}[INFO] $*${RESET}" >&2
    fi
}

function log_status() {
    if [[ $VERBOSE -ge 1 ]]; then
        echo -e "${BLUE}[STATUS] $*${RESET}" >&2
    fi
}

function log_warning() {
    if [[ $VERBOSE -ge 1 ]]; then
        echo -e "${YELLOW}[WARNING] $*${RESET}" >&2
    fi
}

function log_error() {
    echo -e "${RED}[ERROR] $*${RESET}" >&2
}

function log_success() {
    if [[ $VERBOSE -ge 1 ]]; then
        echo -e "${GREEN}[SUCCESS] $*${RESET}" >&2
    fi
}

function check_dependencies() {
    local missing_deps=()
    
    # Check for required commands
    for cmd in find grep awk sed python; do
        if ! command -v "$cmd" &> /dev/null; then
            missing_deps+=("$cmd")
        fi
    done
    
    # Check for Python version and required modules
    if command -v python &> /dev/null; then
        local python_version
        python_version=$(python -c 'import sys; print(f"{sys.version_info.major}.{sys.version_info.minor}")' 2>/dev/null)
        if [[ -z "$python_version" ]]; then
            log_error "Unable to determine Python version"
            exit 1
        fi
        
        log_debug "Found Python version $python_version"
        
        # Check for required Python modules
        local required_modules=("ast" "os" "sys" "re" "json" "multiprocessing")
        local missing_modules=()
        
        for module in "${required_modules[@]}"; do
            if ! python -c "import $module" &> /dev/null; then
                missing_modules+=("$module")
            fi
        done
        
        if [[ ${#missing_modules[@]} -gt 0 ]]; then
            log_error "Missing required Python modules: ${missing_modules[*]}"
            exit 1
        fi
    fi
    
    if [[ ${#missing_deps[@]} -gt 0 ]]; then
        log_error "Missing required dependencies: ${missing_deps[*]}"
        exit 1
    fi
}

function analyze_project() {
    local project_dir="$1"
    
    # Validate project directory
    if [[ ! -d "$project_dir" ]]; then
        log_error "Project directory does not exist or is not a directory: $project_dir"
        exit 1
    fi
    
    project_dir=$(realpath "$project_dir")
    log_status "Analyzing project directory: $project_dir"
    
    # Create a single Python script to handle all operations
    local py_script=$(mktemp)
    
    # Write the comprehensive Python analyzer script
    cat > "$py_script" << 'PYTHON_SCRIPT'
#!/usr/bin/env python3
import sys
import os
import re
import json
import time
from collections import defaultdict
from multiprocessing import Pool, cpu_count, Manager

# A simple regex-based import scanner (faster than AST for our purposes)
def extract_imports_quick(file_path):
    """Extract imports using regex - faster than AST parsing."""
    imports = []
    try:
        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()
        
        # Find all 'import X' statements
        import_statements = re.findall(r'^\s*import\s+([\w\s,\.]+)', content, re.MULTILINE)
        for stmt in import_statements:
            # Handle multiple imports like 'import os, sys, re'
            for module in stmt.split(','):
                module = module.strip()
                # Handle 'import x.y.z'
                base_module = module.split('.')[0]
                imports.append(base_module)
        
        # Find all 'from X import Y' statements
        from_statements = re.findall(r'^\s*from\s+([\w\.]+)\s+import', content, re.MULTILINE)
        for module in from_statements:
            # Handle 'from x.y.z import a'
            base_module = module.split('.')[0]
            imports.append(base_module)
            imports.append(module)
    
    except Exception as e:
        print(f"#ERROR# Failed to process {file_path}: {str(e)}", file=sys.stderr)
        return []
    
    # Remove duplicates and return
    return list(set(imports))

def process_file(args):
    """Process a single Python file and extract imports."""
    file_path, project_dir, only_project = args
    try:
        module_name = normalize_module_name(file_path, project_dir)
        imports = extract_imports_quick(file_path)
        
        # If only analyzing project files, filter imports
        filtered_imports = []
        if only_project == 1:
            for imp in imports:
                if module_exists(imp, project_dir):
                    filtered_imports.append(imp)
        else:
            filtered_imports = imports
        
        return {
            'file': file_path,
            'module': module_name,
            'imports': filtered_imports
        }
    except Exception as e:
        print(f"#ERROR# Failed to process {file_path}: {str(e)}", file=sys.stderr)
        return {
            'file': file_path,
            'module': None,
            'imports': []
        }

def normalize_module_name(file_path, project_dir):
    """Convert file path to module notation."""
    # Remove project directory prefix and .py extension
    rel_path = file_path[len(project_dir)+1:] if file_path.startswith(project_dir) else file_path
    rel_path = rel_path[:-3] if rel_path.endswith('.py') else rel_path
    
    # Handle __init__.py files by using the directory name
    if rel_path.endswith('__init__'):
        rel_path = os.path.dirname(rel_path)
    
    # Convert path to module notation
    return rel_path.replace('/', '.').replace('\\', '.')

def module_exists(module_name, project_dir):
    """Check if a module exists in the project directory."""
    module_path = module_name.replace('.', os.sep)
    for ext in ['.py', os.sep + '__init__.py']:
        if os.path.exists(os.path.join(project_dir, module_path + ext)):
            return True
    return False

def build_dependency_graph(results):
    """Build a dependency graph from processed files."""
    graph = defaultdict(list)
    locations = {}
    
    for result in results:
        module = result['module']
        if not module:
            continue
            
        # Add module location
        locations[module] = result['file']
        
        # Add dependencies
        for imp in result['imports']:
            graph[module].append(imp)
    
    return graph, locations

def find_cycles(graph):
    """Find all cycles in the graph using a DFS-based approach."""
    visited = set()
    path = []
    path_set = set()
    cycles = []
    
    def dfs(node):
        if node in path_set:
            # Found a cycle
            cycle_start = path.index(node)
            cycle = path[cycle_start:] + [node]
            cycles.append(cycle)
            return
        
        if node in visited:
            return
            
        visited.add(node)
        path.append(node)
        path_set.add(node)
        
        for neighbor in graph.get(node, []):
            dfs(neighbor)
        
        path.pop()
        path_set.remove(node)
    
    # Run DFS from each node
    for node in graph:
        if node not in visited:
            dfs(node)
    
    return cycles

def generate_dot_file(graph, output_file):
    """Generate a DOT file for the dependency graph."""
    with open(output_file, 'w') as f:
        f.write("digraph {\n")
        f.write("  rankdir=LR;\n")
        f.write("  node [shape=box, style=filled, fillcolor=lightblue];\n")
        
        for node, neighbors in graph.items():
            for neighbor in neighbors:
                f.write(f'  "{node}" -> "{neighbor}";\n')
        
        f.write("}\n")

def generate_report(cycles, locations, output_file):
    """Generate a report of circular dependencies."""
    with open(output_file, 'w') as f:
        if not cycles:
            f.write("No circular dependencies found.\n")
        else:
            f.write(f"Found {len(cycles)} circular dependencies:\n\n")
            for i, cycle in enumerate(cycles, 1):
                # First write the cycle as module names
                cycle_str = " -> ".join(cycle)
                f.write(f"Cycle {i}: {cycle_str}\n")
                
                # Then write the file locations
                f.write("File locations:\n")
                for module in cycle:
                    if module in locations:
                        f.write(f"  - {module}: {locations[module]}\n")
                    else:
                        f.write(f"  - {module}: <location not found>\n")
                f.write("\n")
    
    # Print number of cycles for bash script
    print(len(cycles))

def main():
    # Parse arguments
    project_dir = sys.argv[1]
    max_workers = int(sys.argv[2])
    only_project = int(sys.argv[3])
    output_file = sys.argv[4] if len(sys.argv) > 4 and sys.argv[4] != "None" else None
    graph_output = sys.argv[5] if len(sys.argv) > 5 and sys.argv[5] != "None" else None
    verbose = int(sys.argv[6]) if len(sys.argv) > 6 else 1
    
    # Find all Python files in the project
    python_files = []
    for root, dirs, files in os.walk(project_dir):
        # Skip excluded directories like __pycache__, .git, etc.
        dirs[:] = [d for d in dirs if d not in ['__pycache__', '.git', '.hg', '.svn', 'venv', 'env', '.venv', '.env']]
        for file in files:
            if file.endswith('.py'):
                python_files.append(os.path.join(root, file))
    
    if verbose >= 2:
        print(f"[INFO] Found {len(python_files)} Python files")
    
    # Process files in parallel
    start_time = time.time()
    
    # Limit workers to number of files and CPU cores
    actual_workers = min(max_workers, len(python_files), cpu_count())
    if verbose >= 2:
        print(f"[INFO] Using {actual_workers} parallel workers")
    
    # Create arguments for each file
    file_args = [(file, project_dir, only_project) for file in python_files]
    
    # Process files in parallel
    results = []
    with Pool(processes=actual_workers) as pool:
        results = pool.map(process_file, file_args)
    
    processing_time = time.time() - start_time
    if verbose >= 2:
        print(f"[INFO] Processing completed in {processing_time:.2f} seconds")
    
    # Build dependency graph
    graph, locations = build_dependency_graph(results)
    
    # Find cycles
    start_time = time.time()
    cycles = find_cycles(graph)
    analysis_time = time.time() - start_time
    
    if verbose >= 2:
        print(f"[INFO] Analysis completed in {analysis_time:.2f} seconds")
    
    # Generate report
    temp_output = "/tmp/daera_output.txt" if not output_file else output_file
    generate_report(cycles, locations, temp_output)
    
    # If output file not specified, print to stdout
    if not output_file:
        with open(temp_output, 'r') as f:
            print(f.read())
        os.remove(temp_output)
    
    # Generate graph visualization if requested
    if graph_output:
        generate_dot_file(graph, graph_output)
    
    # Return the number of cycles found
    return len(cycles)

if __name__ == "__main__":
    try:
        cycle_count = main()
        # Output the cycle count as the very last line, on its own
        print(f"CYCLE_COUNT:{cycle_count}")
    except Exception as e:
        print(f"CYCLE_COUNT:ERROR", file=sys.stderr)
        raise
PYTHON_SCRIPT
    
    # Make the script executable
    chmod +x "$py_script"
    
    # Run the Python analyzer with appropriate arguments
    log_status "Running dependency analysis (this may take a while for large projects)..."
    
    # Execute the analysis script with project settings
    python_output=$("$py_script" "$project_dir" "$MAX_WORKERS" "$ONLY_PROJECT" "$REPORT_FILE" "$GRAPH_OUTPUT" "$VERBOSE")
    
    # Extract the cycle count from the last line 
    FOUND_CYCLES=0
    cycle_count_line=$(echo "$python_output" | grep "CYCLE_COUNT:" | tail -n 1)
    if [[ -n "$cycle_count_line" ]]; then
        FOUND_CYCLES=$(echo "$cycle_count_line" | cut -d':' -f2)
        
        # Remove the cycle count line from the output
        python_output=$(echo "$python_output" | grep -v "CYCLE_COUNT:")
    fi
    
    # If we have output from the script and we're not in quiet mode, display it
    if [[ -n "$python_output" && $VERBOSE -gt 0 ]]; then
        echo "$python_output"
    fi
    
    # If graph output was requested and exists, process it with GraphViz
    if [[ -n "$GRAPH_OUTPUT" && "$GRAPH_OUTPUT" != *.dot && -f "$GRAPH_OUTPUT" ]]; then
        if ! command -v dot &> /dev/null; then
            log_warning "GraphViz (dot) command not found. Saving as DOT file."
        else
            temp_dot="${GRAPH_OUTPUT}.dot.tmp"
            mv "$GRAPH_OUTPUT" "$temp_dot"
            
            log_status "Generating visual dependency graph at $GRAPH_OUTPUT..."
            
            if [[ "$GRAPH_OUTPUT" == *.png ]]; then
                dot -Tpng "$temp_dot" -o "$GRAPH_OUTPUT"
            elif [[ "$GRAPH_OUTPUT" == *.svg ]]; then
                dot -Tsvg "$temp_dot" -o "$GRAPH_OUTPUT"
            elif [[ "$GRAPH_OUTPUT" == *.pdf ]]; then
                dot -Tpdf "$temp_dot" -o "$GRAPH_OUTPUT"
            fi
            
            if [[ $? -eq 0 ]]; then
                log_success "Dependency graph saved to $GRAPH_OUTPUT"
                rm -f "$temp_dot"
            else
                log_error "Failed to generate dependency graph"
                # Restore the original DOT file if GraphViz fails
                mv "$temp_dot" "$GRAPH_OUTPUT"
            fi
        fi
    fi
    
    # Clean up
    rm -f "$py_script"
    
    # Report findings
    if [[ "$FOUND_CYCLES" -gt 0 ]]; then
        log_error "Found $FOUND_CYCLES circular dependencies."
        return 1
    else
        log_success "No circular dependencies found!"
        return 0
    fi
}

# -------- Main Script --------

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case "$1" in
        -h|--help)
            show_help
            exit 0
            ;;
        -v|--verbose)
            VERBOSE=$((VERBOSE + 1))
            shift
            ;;
        -vv)
            VERBOSE=$((VERBOSE + 2))
            shift
            ;;
        -q|--quiet)
            VERBOSE=0
            shift
            ;;
        -o|--output)
            REPORT_FILE="$2"
            shift 2
            ;;
        -g|--graph)
            GRAPH_OUTPUT="$2"
            shift 2
            ;;
        -e|--exclude)
            if [[ -z "$EXCLUDE_DIRS" ]]; then
                EXCLUDE_DIRS="$2"
            else
                EXCLUDE_DIRS="$EXCLUDE_DIRS,$2"
            fi
            shift 2
            ;;
        -f|--exclude-file)
            if [[ -z "$EXCLUDE_FILES" ]]; then
                EXCLUDE_FILES="$2"
            else
                EXCLUDE_FILES="$EXCLUDE_FILES,$2"
            fi
            shift 2
            ;;
        -d|--max-depth)
            MAX_DEPTH="$2"
            shift 2
            ;;
        -j|--jobs)
            MAX_WORKERS="$2"
            shift 2
            ;;
        -a|--all)
            ONLY_PROJECT=0
            shift
            ;;
        -*)
            log_error "Unknown option: $1"
            show_help
            exit 1
            ;;
        *)
            PROJECT_DIR="$1"
            shift
            ;;
    esac
done

show_banner

# Check if a project directory was specified
if [[ -z "$PROJECT_DIR" ]]; then
    show_help
    exit 0
fi

check_dependencies
analyze_project "$PROJECT_DIR"
exit_code=$?

exit $exit_code